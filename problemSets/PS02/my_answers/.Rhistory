amlo <- readRDS("/Users/sarabcidf/Desktop/ASDS/Dissertation/AMLO/Scraping/amlo_press_conferences.rds")
amlo$word_count <- sapply(amlo$text, function(x) length(strsplit(x, "\\s+")[[1]]))
View(amlo)
library(tidyverse)
amlo$word_count <- sapply(amlo$text, function(x) length(strsplit(x, "\\s+")[[1]]))
amlo$date <- as.Date(amlo$date, format="%B %d, %Y")
amlo <- amlo[order(amlo$date), ]
ggplot(amlo, aes(x=date, y=word_count)) +
geom_line() + # For a line plot
geom_point() + # To add points on each date
theme_minimal() + # A minimal theme for aesthetics
labs(title="Word Count of Press Conferences Over Time",
x="Date",
y="Word Count")
all(is.finite(amlo$word_count))
ggplot(amlo, aes(x=date, y=word_count)) +
geom_line() + # For a line plot
geom_point() + # To add points on each date
theme_minimal() + # A minimal theme for aesthetics
labs(title="Word Count of Press Conferences Over Time",
x="Date",
y="Word Count")
View(amlo)
amlo <- readRDS("/Users/sarabcidf/Desktop/ASDS/Dissertation/AMLO/Scraping/amlo_press_conferences.rds")
View(amlo)
library(lubridate)
amlo$date <- parse_date_time(amlo$date, orders = "b d, Y")
amlo <- readRDS("/Users/sarabcidf/Desktop/ASDS/Dissertation/AMLO/Scraping/amlo_press_conferences.rds")
View(amlo)
months_spanish_to_english <- setNames(
c("January", "February", "March", "April", "May", "June", "July", "August", "September", "October", "November", "December"),
c("enero", "febrero", "marzo", "abril", "mayo", "junio", "julio", "agosto", "septiembre", "octubre", "noviembre", "diciembre")
)
# Function to replace Spanish month names with English in a date string
replace_month_names <- function(date_string) {
for(spanish in names(months_spanish_to_english)) {
english <- months_spanish_to_english[spanish]
date_string <- gsub(spanish, english, date_string, ignore.case = TRUE)
}
return(date_string)
}
# Apply the replacement to the date column
amlo$date <- sapply(amlo$date, replace_month_names)
# Now convert the modified date strings to Date objects
amlo$date <- as.Date(amlo$date, format="%B %d, %Y")
amlo$word_count <- sapply(amlo$text, function(x) length(strsplit(x, "\\s+")[[1]]))
amlo$date <- parse_date_time(amlo$date, orders = "m d, Y")
amlo <- amlo[order(amlo$date), ]
View(amlo)
amlo <- readRDS("/Users/sarabcidf/Desktop/ASDS/Dissertation/AMLO/Scraping/amlo_press_conferences.rds")
# Fixing dates:
months_spanish_to_english <- setNames(
c("January", "February", "March", "April", "May", "June", "July", "August", "September", "October", "November", "December"),
c("enero", "febrero", "marzo", "abril", "mayo", "junio", "julio", "agosto", "septiembre", "octubre", "noviembre", "diciembre")
)
# Function to replace Spanish month names with English in a date string
replace_month_names <- function(date_string) {
for(spanish in names(months_spanish_to_english)) {
english <- months_spanish_to_english[spanish]
date_string <- gsub(spanish, english, date_string, ignore.case = TRUE)
}
return(date_string)
}
# Apply the replacement to the date column
amlo$date <- sapply(amlo$date, replace_month_names)
# Now convert the modified date strings to Date objects
amlo$date <- as.Date(amlo$date, format="%B %d, %Y")
View(amlo)
# Calculate word count for each press conference
amlo$word_count <- sapply(amlo$text, function(x) length(strsplit(x, "\\s+")[[1]]))
View(amlo)
View(amlo)
ggplot(amlo, aes(x = date, y = word_count)) +
geom_line() +  # Connect points with lines to see trends over time
geom_point() +  # Add points for each press conference
theme_minimal() +  # Use a minimal theme for aesthetics
labs(title = "Word Count of Press Conferences Over Time",
x = "Date",
y = "Word Count")
ggplot(amlo, aes(x = date, y = word_count)) +
geom_point() +  # Connect points with lines to see trends over time
theme_minimal() +  # Use a minimal theme for aesthetics
labs(title = "Word Count of Press Conferences Over Time",
x = "Date",
y = "Word Count")
ggplot(amlo, aes(x = year, y = word_count)) +
geom_boxplot() +
theme_minimal() +
labs(title = "Variation in Press Conference Length Over Years",
x = "Year",
y = "Word Count")
# Create 'year' and 'month' columns from the 'date' column
amlo$year <- format(amlo$date, "%Y")
amlo$month <- format(amlo$date, "%m")
# Combine 'year' and 'month' for monthly aggregation
amlo$year_month <- paste(amlo$year, amlo$month, sep = "-")
ggplot(amlo, aes(x = year, y = word_count)) +
geom_boxplot() +
theme_minimal() +
labs(title = "Variation in Press Conference Length Over Years",
x = "Year",
y = "Word Count")
# Monthly frequency of conferences
ggplot(monthly_counts, aes(x = year_month, y = count)) +
geom_line() +  # Connect points with lines
geom_point() +  # Add points for each month
theme_minimal() +  # Use a minimal theme
scale_x_date(date_breaks = "1 year", date_labels = "%Y") +  # Configure the x-axis to show each year
labs(title = "Frequency of Press Conferences Per Month",
x = "Month",
y = "Number of Press Conferences") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis labels for better readability
monthly_counts <- amlo %>%
group_by(year_month) %>%
summarise(count = n())
ggplot(monthly_counts, aes(x = year_month, y = count)) +
geom_line() +  # Connect points with lines
geom_point() +  # Add points for each month
theme_minimal() +  # Use a minimal theme
scale_x_date(date_breaks = "1 year", date_labels = "%Y") +  # Configure the x-axis to show each year
labs(title = "Frequency of Press Conferences Per Month",
x = "Month",
y = "Number of Press Conferences") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis label
monthly_counts$year_month <- as.Date(paste0(monthly_counts$year_month, "-01"))
ggplot(monthly_counts, aes(x = year_month, y = count)) +
geom_line() +  # Connect points with lines
geom_point() +  # Add points for each month
theme_minimal() +  # Use a minimal theme
scale_x_date(date_breaks = "1 year", date_labels = "%Y") +  # Configure the x-axis to show each year
labs(title = "Frequency of Press Conferences Per Month",
x = "Month",
y = "Number of Press Conferences") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))  # R
# remove objects
rm(list=ls())
# detach all libraries
detachAllPackages <- function() {
basic.packages <- c("package:stats", "package:graphics", "package:grDevices", "package:utils", "package:datasets", "package:methods", "package:base")
package.list <- search()[ifelse(unlist(gregexpr("package:", search()))==1, TRUE, FALSE)]
package.list <- setdiff(package.list, basic.packages)
if (length(package.list)>0)  for (package in package.list) detach(package,  character.only=TRUE)
}
detachAllPackages()
# load libraries
pkgTest <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[,  "Package"])]
if (length(new.pkg))
install.packages(new.pkg,  dependencies = TRUE)
sapply(pkg,  require,  character.only = TRUE)
}
# here is where you load any necessary packages
# ex: stringr
# lapply(c("stringr"),  pkgTest)
lapply(c(),  pkgTest)
# set wd for current folder
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# load data
load(url("https://github.com/ASDS-TCD/StatsII_Spring2024/blob/main/datasets/climateSupport.RData?raw=true"))
View(climateSupport)
View(climateSupport)
climate_logit <- glm(choice ~ countries + sanctions, data = climateSupport,
family = binomial(link = logit))
summary(climate_logit)
head(climateSupport)
View(climateSupport)
climateSupport$sanctions <- relevel(climateSupport$sanctions, ref = "None")
climateSupport$sanctions <- factor(climateSupport$sanctions, ordered = FALSE)
climateSupport$countries <- factor(climateSupport$countries, ordered = FALSE)
climateSupport$sanctions <- relevel(climateSupport$sanctions, ref = "None")
climateSupport$countries <- relevel(climateSupport$countries, ref = "20 of 192")
climate_logit <- glm(choice ~ countries + sanctions, data = climateSupport,
family = binomial(link = logit))
summary(climate_logit)
lapply(c("tidyverse"),  pkgTest)
stargazer(climate_logit, type = "latex", title = "Model Summary", header = FALSE,
model.names = FALSE, significance.levels = c(0.05, 0.01, 0.001),
out = "model_summary.tex")
lapply(c("stargazer"),  pkgTest)
stargazer(climate_logit, type = "latex", title = "Model Summary", header = FALSE,
model.names = FALSE, significance.levels = c(0.05, 0.01, 0.001),
out = "model_summary.tex")
stargazer(climate_logit, type = "text", title = "Model Summary", header = FALSE,
model.names = FALSE, significance.levels = c(0.05, 0.01, 0.001))
summary(climateSupport)
climateSupport$sanctions2 <- relevel(climateSupport$sanctions, ref = "5%")
# Fitting again:
climate_logit2 <- glm(choice ~ countries + sanctions2, data = climateSupport,
family = binomial(link = logit))
# Looking at the results:
summary(climate_logit2)
# Reporting:
stargazer(climate_logit2, type = "text", title = "Model Summary", header = FALSE,
model.names = FALSE, significance.levels = c(0.05, 0.01, 0.001))
stargazer(climate_logit2, type = "latex", title = "Model Summary", header = FALSE,
model.names = FALSE, significance.levels = c(0.05, 0.01, 0.001))
filtered_data <- climateSupport %>%
filter(countries == "80 of 192", sanctions == "None")
predicted_prob <- predict(model, newdata = filtered_data, type = "response")
filtered_data <- climateSupport %>%
filter(countries == "80 of 192", sanctions == "None")
predicted_prob <- predict(climate_logit, newdata = filtered_data, type = "response")
predicted_prob
summary(predicted_prob)
probability <- function(b0, b1, xi) {
1 / (1 + exp(-(b0 + b1 * xi)))
}
filtered_data <- climateSupport %>%
filter(countries == "80 of 192", sanctions == "None")
# Creating function based on slide 40, W4:
probability <- function(b0, b_countries, xi_countries = 1) {
prob <- 1 / (1 + exp(-(b0 + b_countries * xi_countries)))
return(prob)
}
coefficients <- coef(climate_logit)
b0 <- coefficients['(Intercept)']
b_countries <- coefficients['countries80 of 192'] # Adjust if the name in your model is different
prob_support <- probability(b0, b_countries)
prob_support
predicted_prob2 <- predict(climate_logit, newdata = filtered_data, type = "response")
summary(predicted_prob2)
calculate_probability <- function(model, newdata) {
# Ensure newdata is a dataframe with the same predictors as the model
if (!is.data.frame(newdata)) {
stop("newdata must be a dataframe")
}
# Extract model coefficients
coefficients <- coef(model)
# Match predictors in newdata with coefficients, including intercept
predictors <- names(coefficients)
matched_predictors <- match(predictors, names(newdata))
# Calculate linear predictors (eta = b0 + b1*x1 + b2*x2 + ...)
eta <- coefficients['(Intercept)'] # Start with intercept
for (i in matched_predictors) {
if (!is.na(i)) { # If predictor found in newdata
eta <- eta + coefficients[i] * newdata[, i]
}
}
# Calculate probability
probability <- 1 / (1 + exp(-eta))
return(probability)
}
new_observation <- data.frame(countries = factor("80 of 192", levels = levels(climateSupport$countries)),
sanctions = factor("None", levels = levels(climateSupport$sanctions)))
# Calculate probability
prob_support <- calculate_probability(climate_logit, new_observation)
print(prob_support)
probability <- function(b0, b1, xi) {
1 / (1 + exp(-(b0 + b1 * xi)))
}
coefficients <- coef(climate_logit)
b0 <- coefficients['(Intercept)']
b1 <- coefficients['countries80 of 192'] # This is dependent to this case
prob_support <- probability(b0, b1)
# Sanctions = None,
# Countries = 80 out of 192...
filtered_data <- climateSupport %>%
filter(countries == "80 of 192", sanctions == "None")
# Creating function based on slide 40, W4:
probability <- function(b0, b1, xi) {
1 / (1 + exp(-(b0 + b1 * xi)))
}
coefficients <- coef(climate_logit)
b0 <- coefficients['(Intercept)']
b1 <- coefficients['countries80 of 192'] # This is dependent to this case
prob_support <- probability(b0, b1, xi = 1)
prob_support
predicted_prob2 <- predict(climate_logit, newdata = filtered_data, type = "response")
summary(predicted_prob2)
climate_logit_int <- glm(choice ~ countries + sanctions2 + countries*sanctions2,
data = climateSupport,
family = binomial(link = logit))
# Looking at the results:
summary(climate_logit_int)
climate_logit_int <- glm(choice ~ countries + sanctions + countries*sanctions,
data = climateSupport,
family = binomial(link = logit))
# Looking at the results:
summary(climate_logit_int)
stargazer(climate_logit, climate_logit_int, type = "text", title = "Model Summary", header = FALSE,
model.names = FALSE, significance.levels = c(0.05, 0.01, 0.001))
summary(climate_logit)
summary(climate_logit_int)
stargazer(climate_logit, climate_logit_int, type = "text", title = "Model Summary", header = FALSE,
model.names = FALSE, significance.levels = c(0.05, 0.01, 0.001))
stargazer(climate_logit, climate_logit_int, type = "text",
title = "Models Comparison", out = "models_comparison.txt",
model.names = FALSE, header = FALSE,
significance.levels = c(0.05, 0.01, 0.001))
cl <- climate_logit
cli <- climate_logit_int
stargazer(cl, cli, type = "text", title = "Model Summary", header = FALSE,
model.names = FALSE, significance.levels = c(0.05, 0.01, 0.001))
summary(climate_logit)
stargazer(climate_logit, type = "text", title = "Model Summary", header = FALSE,
model.names = FALSE, significance.levels = c(0.05, 0.01, 0.001),
report=('vc*p'))
stargazer(climate_logit, type = "text", title = "Model Summary", header = FALSE,
model.names = FALSE, significance.levels = c(0.05, 0.01, 0.001),
report=('vc*p'),
add.lines = list(c("Number of Fisher Scoring iterations", "4")))
stargazer(climate_logit, type = "latex", title = "Model Summary", header = FALSE,
model.names = FALSE, significance.levels = c(0.05, 0.01, 0.001),
report=('vc*p'),
add.lines = list(c("Number of Fisher Scoring iterations", "4")))
stargazer(climate_logit, type = "text", title = "Model Summary", header = FALSE,
model.names = FALSE, significance.levels = c(0.05, 0.01, 0.001),
report=('vc*p'),
add.lines = list(c("Number of Fisher Scoring iterations", "4")))
# Transformation of results:
b_countries_80_of_192 <- 0.336
b_countries_160_of_192 <- 0.648
b_sanctions_5_percent <- 0.192
b_sanctions_15_percent <- -0.133
b_sanctions_20_percent <- -0.304
# Transforming from "effect on log odds" to "effect on odds":
odds_80_countries <- exp(b_countries_80_of_192)
odds_160_countries <- exp(b_countries_160_of_192)
odds_sanctions_5_percent <- exp(b_sanctions_5_percent)
odds_sanctions_15_percent <- exp(b_sanctions_15_percent)
odds_sanctions_20_percent <- exp(b_sanctions_20_percent)
# Transforming from "effect on odds" to "effect on probability":
prob_80_countries <- odds_80_countries / (1 + odds_80_countries)
prob_160_countries <- odds_160_countries / (1 + odds_160_countries)
prob_sanctions_5_percent <- odds_sanctions_5_percent / (1 + odds_sanctions_5_percent)
prob_sanctions_15_percent <- odds_sanctions_15_percent / (1 + odds_sanctions_15_percent)
prob_sanctions_20_percent <- odds_sanctions_20_percent / (1 + odds_sanctions_20_percent)
results_df <- data.frame(
Variable = c("80 of 192 countries", "160 of 192 countries", "Sanctions 5%", "Sanctions 15%", "Sanctions 20%"),
Odds = c(odds_80_countries, odds_160_countries, odds_sanctions_5_percent, odds_sanctions_15_percent, odds_sanctions_20_percent),
Probability = c(prob_80_countries, prob_160_countries, prob_sanctions_5_percent, prob_sanctions_15_percent, prob_sanctions_20_percent)
)
View(results_df)
lapply(c("stargazer","stargazer","knitr"),  pkgTest)
results_tex <- kable(results_df, format = "latex", caption = "Effects of Countries Participation and Sanctions on Policy Support", booktabs = TRUE)
print(latex_table)
print(results_tex)
stargazer(results_df, type = "latex",
title = "Effects of Countries Participation and Sanctions on Policy Support",
header = FALSE, summary = FALSE)
transf_results <- data.frame(
Variable = c("80 of 192 countries", "160 of 192 countries", "Sanctions 5%", "Sanctions 15%", "Sanctions 20%"),
Odds = c(odds_80_countries, odds_160_countries, odds_sanctions_5_percent, odds_sanctions_15_percent, odds_sanctions_20_percent),
Probability = c(prob_80_countries, prob_160_countries, prob_sanctions_5_percent, prob_sanctions_15_percent, prob_sanctions_20_percent)
)
stargazer(transf_results, type = "latex",
title = "Effects of Countries Participation and Sanctions on Policy Support",
header = FALSE, summary = FALSE)
null_logit <- glm(choice ~ 1, data = climateSupport, family = binomial(link = "logit"))
lrt_result <- anova(null_logit, climate_logit, test = "Chisq")
null_logit <- glm(choice ~ 1, data = climateSupport, family = binomial(link = "logit"))
lrt_result <- anova(null_logit, climate_logit, test = "Chisq")
summary(null_logit)
anova(null_logit, climate_logit, test = "Chisq")
null_logit <- glm(choice ~ 1, data = climateSupport, family = binomial(link = "logit"))
summary(null_logit)
anova(null_logit, climate_logit, test = "LRT")
null_logit <- glm(choice ~ 1, data = climateSupport, family = binomial(link = "logit"))
summary(null_logit)
anova_test <- anova(null_logit, climate_logit, test = "LRT")
summary(anova_test)
anova(null_logit, climate_logit, test = "LRT")
anova_test <- anova(null_logit, climate_logit, test = "LRT")
anova_test
null_logit <- glm(choice ~ 1, data = climateSupport, family = binomial(link = "logit"))
summary(null_logit)
anova_test <- anova(null_logit, climate_logit, test = "LRT")
anova_test
anova_table <- as.data.frame(anova_test)
View(anova_table)
stargazer(null_logit, type = "latex",
title = "Summary of Null Logistic Regression Model")
anova_table <- as.data.frame(anova_test)
stargazer(anova_table, type = "latex",
title = "LRT Results")
View(anova_table)
View(anova_table)
stargazer(anova_table, type = "latex", summary = list(anova_table),
title = "LRT Results")
stargazer(anova_table, type = "text",
title = "LRT Results")
stargazer(anova_table, type = "text", summary = anova_table
title = "LRT Results")
stargazer(anova_table, type = "text", summary = list(anova_table),
title = "LRT Results")
View(anova_table)
anova_table
stargazer(anova_table, type = "text",
title = "LRT Results")
stargazer(anova_table, type = "latex",
title = "LRT Results")
# Changing the reference category to 5% sanctions to be able to interpret directly:
climateSupport$sanctions2 <- relevel(climateSupport$sanctions, ref = "5%")
# Fitting again:
climate_logit2 <- glm(choice ~ countries + sanctions2, data = climateSupport,
family = binomial(link = logit))
# Looking at the results:
summary(climate_logit2)
# Changing the reference category to 5% sanctions to be able to interpret directly:
climateSupport$sanctions2 <- relevel(climateSupport$sanctions, ref = "5%")
# Fitting again:
climate_logit2 <- glm(choice ~ countries + sanctions2, data = climateSupport,
family = binomial(link = logit))
# Looking at the results:
summary(climate_logit2)
stargazer(climate_logit2, type = "latex", title = "Model Summary", header = FALSE,
model.names = FALSE, significance.levels = c(0.05, 0.01, 0.001),
report=('vc*p'),
add.lines = list(c("Number of Fisher Scoring iterations", "4")))
coef5to15 <- -0.32510
coef5to15 <- -0.32510
odds <- exp(coef5to15)
prob <- odds / (1 + odds)
odds
prob
stargazer(climate_logit2, type = "latex", title = "Model Summary", header = FALSE,
model.names = FALSE, significance.levels = c(0.05, 0.01, 0.001),
report=('vc*p'),
add.lines = list(c("Number of Fisher Scoring iterations", "4")))
stargazer(climate_logit2, type = "latex", title = "Model Summary", header = FALSE,
model.names = FALSE, significance.levels = c(0.05, 0.01, 0.001),
report=('vc*p'),
add.lines = list(c("Number of Fisher Scoring iterations", "4")))
# Transforming for odds and probability:
coef5to15 <- -0.32510
odds <- exp(coef5to15)
prob <- odds / (1 + odds)
odds
prob
prob_support
stargazer(anova_test2, type = "latex",
title = "LRT Results")
climate_logit_int <- glm(choice ~ countries + sanctions + countries*sanctions,
data = climateSupport,
family = binomial(link = logit))
# LRT:
anova_test2 <- anova(climate_logit, climate_logit_int, test = "LRT")
anova_test2
anova_table <- as.data.frame(anova_test2)
# Reporting:
stargazer(anova_test2, type = "latex",
title = "LRT Results")
stargazer(climate_logit_int, type = "latex",
title = "Summary of Null Logistic Regression Model")
stargazer(anova_test2, type = "latex",
title = "LRT Results")
stargazer(climate_logit_int, type = "latex",
title = "Summary of Null Logistic Regression Model")
stargazer(cl, cli, type = "latex", title = "Model Summary", header = FALSE,
model.names = FALSE, significance.levels = c(0.05, 0.01, 0.001),
report=('vc*p'),
add.lines = list(c("Number of Fisher Scoring iterations", "4")))
stargazer(climate_logit, type = "text", title = "Model Summary", header = FALSE,
model.names = FALSE, significance.levels = c(0.05, 0.01, 0.001),
add.lines = list(c("Number of Fisher Scoring iterations", "4")))
stargazer(climate_logit, type = "latex", title = "Model Summary", header = FALSE,
model.names = FALSE, significance.levels = c(0.05, 0.01, 0.001),
add.lines = list(c("Number of Fisher Scoring iterations", "4")))
